{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LogisticRegressionTitanicDataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO2MhRsDexOZLwdKubeHZ2p"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIBgrJKsYXL6"
      },
      "source": [
        "%tensorflow_version 2.x  "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUYH5VRVXj2l"
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import matplotlib.pyplot as plt \n",
        "from IPython.display import clear_output \n",
        "\n",
        "import tensorflow as tf \n",
        "from tensorflow import feature_column "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7svgLCQ3Yk50"
      },
      "source": [
        "# Load our training and test data \n",
        "dftrain = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/train.csv') # training dataset\n",
        "dfeval = pd.read_csv('https://storage.googleapis.com/tf-datasets/titanic/eval.csv') # testing dataset\n",
        "#print(dftrain.head())\n",
        "\n",
        "y_train = dftrain.pop('survived') # pop survived data from dataframe, this is the data we want to isolate and do the regression on \n",
        "y_eval = dfeval.pop('survived') "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkOciOfLZTt_",
        "outputId": "1b1992d8-82e3-4ee7-de9c-3466072f57b0"
      },
      "source": [
        "# Observe and get to know structure and characteristics of data (Not Required to train Model)\n",
        "\n",
        "# dftrain.describe() # prints out stats about data such as mean, std, etc.\n",
        "dftrain.info() #prints out all the columns in data and the data type used to represent each (helpful for determining categorical/numerical)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 627 entries, 0 to 626\n",
            "Data columns (total 9 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   sex                 627 non-null    object \n",
            " 1   age                 627 non-null    float64\n",
            " 2   n_siblings_spouses  627 non-null    int64  \n",
            " 3   parch               627 non-null    int64  \n",
            " 4   fare                627 non-null    float64\n",
            " 5   class               627 non-null    object \n",
            " 6   deck                627 non-null    object \n",
            " 7   embark_town         627 non-null    object \n",
            " 8   alone               627 non-null    object \n",
            "dtypes: float64(2), int64(2), object(5)\n",
            "memory usage: 44.2+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEH9Q7tMxCaw"
      },
      "source": [
        "dftrain.hist(bins=20)\n",
        "# print(type(dftrain))\n",
        "# for item in NUMERICAL_COLUMNS: \n",
        "#   dftrain[item].hist(bins=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G73ICfeRbem-"
      },
      "source": [
        "# Observe and get to know structure and characteristics of data (Not Required to train Model)\n",
        "dftrain['sex'].value_counts().plot(kind='bar')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzqtXBspbhWY"
      },
      "source": [
        "# Observe and get to know structure and characteristics of data (Not Required to train Model)\n",
        "dftrain['class'].value_counts().plot(kind='bar')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7XwJyYBmrT4"
      },
      "source": [
        "# setup features for model \n",
        "\n",
        "# CATEGORICAL_COLUMNS = ['sex', 'n_siblings_spouses', 'parch', 'class', 'deck', 'embark_town', 'alone']\n",
        "# NUMERICAL_COLUMNS = ['age', 'fare']\n",
        "\n",
        "CATEGORICAL_COLUMNS = ['sex', 'class', 'deck', 'embark_town', 'alone']\n",
        "NUMERICAL_COLUMNS = ['age', 'fare', 'n_siblings_spouses', 'parch']\n",
        "\n",
        "feature_columns = [] \n",
        "\n",
        "# iterate through categorical columns\n",
        "for feature_name in CATEGORICAL_COLUMNS: \n",
        "    vocabulary = dftrain[feature_name].unique() # get all the unique values for each category (ex. Sex would M/F)\n",
        "    new_feature = tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary) # creates a feature for a category and all the unique entries\n",
        "    feature_columns.append(tf.feature_column.categorical_column_with_vocabulary_list(feature_name, vocabulary)) # add the feature to the list  \n",
        "\n",
        "# iterate through numerical columns \n",
        "for feature_name in NUMERICAL_COLUMNS: \n",
        "    new_feature = tf.feature_column.numeric_column(feature_name, dtype = tf.float32) # create a feature with the category and a float value\n",
        "    feature_columns.append(new_feature) # give feature name and data type for numeric # add the features to the list"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vyz_JV8Bne9x"
      },
      "source": [
        "# Create an input function that will convert our pandas dataframe into a tf.data.dataset obj, source: https://www.tensorflow.org/tutorials/estimator/linear\n",
        "def make_input_fn(data_df, label_df, num_epochs=10, shuffle=True, batch_size=100):\n",
        "  def input_function():  # Nested function \n",
        "    ds = tf.data.Dataset.from_tensor_slices((dict(data_df), label_df))  # create tf.data.Dataset object with data and its label\n",
        "    if shuffle:\n",
        "      ds = ds.shuffle(1000)  # randomize order of data\n",
        "    ds = ds.batch(batch_size).repeat(num_epochs)  # split dataset into batches of 32 and repeat process for number of epochs\n",
        "    # example of repeat and batch method are used:\n",
        "    # repeat: [1, 2, 3].repeat(3) -> [1, 2, 3, 1, 2, 3, 1, 2, 3]\n",
        "    # batch: dataset = tf.data.Dataset.range(8).batch(3) -> [[0, 1, 2], [3, 4, 5], [6, 7]]\n",
        "    return ds  # return batch \n",
        "  return input_function  # return dataset object \n",
        "\n",
        "train_input_fn = make_input_fn(dftrain, y_train)  # here we will call the input_function that was returned to us to get a dataset object we can feed to the model\n",
        "eval_input_fn = make_input_fn(dfeval, y_eval, num_epochs=1, shuffle=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NptvKIBpmP8"
      },
      "source": [
        "# Create model with feature columns \n",
        "linear_est = tf.estimator.LinearClassifier(feature_columns=feature_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmdbxDZsr2k2"
      },
      "source": [
        "# train model with function \n",
        "linear_est.train(train_input_fn)  # train\n",
        "result = linear_est.evaluate(eval_input_fn)  # get model accuracy on tetsing data\n",
        "\n",
        "clear_output()\n",
        "print(result['accuracy'])  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fGz0Sbho4dxH"
      },
      "source": [
        "predictions = list(linear_est.predict(eval_input_fn)) # should be an object containing probabilities, class_ids...\n",
        "\n",
        "probs = pd.Series([pred['probabilities'][1] for pred in predictions])\n",
        "probs.plot(kind='hist', bins=20, title='predicted probabilities')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}